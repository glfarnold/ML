{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb773b4b",
   "metadata": {},
   "source": [
    "# Exercise 10- Stacking\n",
    "\n",
    "In this exercise you will implement an ensemble method by learning a stacked regressor.\n",
    "\n",
    "- paul.kahlmeyer@uni-jena.de\n",
    "\n",
    "### Submission\n",
    "- Deadline of submission:\n",
    "        21.06.23 23:59\n",
    "- Submission on [moodle page](https://moodle.uni-jena.de/course/view.php?id=43681)\n",
    "\n",
    "\n",
    "### Help\n",
    "In case you cannot solve a task, you can use the saved values within the `help` directory:\n",
    "- Load arrays with [Numpy](https://numpy.org/doc/stable/reference/generated/numpy.load.html)\n",
    "```\n",
    "np.load('help/array_name.npy')\n",
    "```\n",
    "- Load functions with [Dill](https://dill.readthedocs.io/en/latest/dill.html)\n",
    "```\n",
    "import dill\n",
    "with open('help/some_func.pkl', 'rb') as f:\n",
    "    func = dill.load(f)\n",
    "```\n",
    "\n",
    "to continue working on the other tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27cc77",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "\n",
    "We will use a real world dataset used for predicting the [quality of red wine](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009).\n",
    "Altough the quality is a discrete value between 0 and 10, we interpret it as a regression task. \n",
    "\n",
    "### Task 1\n",
    "\n",
    "Load the dataset stored in `dataset.csv` and split it into `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "774f6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f1b087f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape: (1599, 11)\n",
      "Target variable (y) shape: (1599, 1)\n"
     ]
    }
   ],
   "source": [
    "# TODO: load data\n",
    "# Load the dataset\n",
    "data = np.loadtxt('dataset.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = data[:, :-1]  # All columns except the last one\n",
    "y = data[:, -1].reshape(-1, 1)  # Last column\n",
    "\n",
    "# Print the shapes of X and y\n",
    "print(\"Features (X) shape:\", X.shape)\n",
    "print(\"Target variable (y) shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b222bb8",
   "metadata": {},
   "source": [
    "## $R^2$ Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683ff45",
   "metadata": {},
   "source": [
    "Sklearn uses the [$R^2$ score](https://en.wikipedia.org/wiki/Coefficient_of_determination) as a quality measure for regressors. Given true values $y$ and predicted values $\\hat{y}$ the $R^2$ score is defined as \n",
    "\n",
    "\\begin{align*}\n",
    "R^2(y, \\hat{y}) &= 1-\\cfrac{\\sum_{i=1}^m(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^m(y_i - \\bar{y})^2}\\,,\n",
    "\\end{align*}\n",
    "where $\\bar{y}$ is the average of $y$.\n",
    "\n",
    "This value is 1 if the predictions match exactly, 0 if we would simply always predict the average and negative if our predictions are worse than this simple baseline.\\\n",
    "In short we aim for a value $>0$ and close to $1$.\n",
    "\n",
    "### Task 2\n",
    "\n",
    "Implement the $R^2$ score.\\\n",
    "Then use scikit learns [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) model to fit on the dataset and calculate the $R^2$ score.\\\n",
    "Compare your result to the `.score` method of the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6302e258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.3605517030386881\n"
     ]
    }
   ],
   "source": [
    "def r2_score(y, y_hat):\n",
    "    '''\n",
    "    Calculates coefficient of determination.\n",
    "\n",
    "    @Params:\n",
    "        y... true labels\n",
    "        y_hat... predicted labels\n",
    "\n",
    "    @Returns:\n",
    "        score in (-inf, 1)\n",
    "    '''\n",
    "    return 1 - (np.sum((y - y_hat) ** 2) / np.sum((y - np.mean(y)) ** 2))\n",
    "\n",
    "# Create and fit the Linear Regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n",
    "\n",
    "# Calculate R2 score using the custom function\n",
    "y_pred = regressor.predict(X)\n",
    "r2_custom = r2_score(y, y_pred)\n",
    "\n",
    "# Calculate R2 score using the score() method of the Linear Regression model\n",
    "r2_builtin = regressor.score(X, y)\n",
    "\n",
    "assert(r2_custom == r2_builtin)\n",
    "\n",
    "print(\"R2 score:\", r2_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13700b8d",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "The main idea in stacking is to \n",
    "1. learn several heterogenous base models on the original data\n",
    "2. learn a meta model on the predictions of the base models\n",
    "\n",
    "<div>\n",
    "<img src=\"images/stacking.png\" width=\"600\"/>\n",
    "</div>\n",
    "The hope is that the meta model can learn to combine the strengths of the base models (e.g. if model 1 fails, model 3 is strong).\n",
    "Note that in contrast to bagging and boosting the base models must not be of the same method (e.g. decision trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdb752",
   "metadata": {},
   "source": [
    "## Base Models\n",
    "\n",
    "First lets select a set of base models. We can now choose from the wide pool of regression methods.\n",
    "\n",
    "Here we want to use the following models:\n",
    "- [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- Polynomial Regression of degree 2 (use a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) of [Polynomial Features](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) followed by Linear Regression)\n",
    "- [KNN Regression](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
    "- [Decision Tree Regression](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2f1a5",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Create a list of base models and evaluate them using crossvalidation (avg. of 10 folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e3c0d0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model 1: 0.2355470969430759\n",
      "Base Model 2: 0.1902292194320662\n",
      "Base Model 3: -0.07634595535227609\n",
      "Base Model 4: -0.5315458182226246\n"
     ]
    }
   ],
   "source": [
    "# TODO: create base models\n",
    "# Create a list of base models\n",
    "base_models = [\n",
    "    LinearRegression(),\n",
    "    make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "    KNeighborsRegressor(),\n",
    "    DecisionTreeRegressor()\n",
    "]\n",
    "\n",
    "# TODO: estimate avg. crossvalidation score for each base model\n",
    "# Perform cross-validation for each base model\n",
    "cv_scores = []\n",
    "for model in base_models:\n",
    "    scores = cross_val_score(model, X, y, cv=10)\n",
    "    avg_score = np.mean(scores)\n",
    "    cv_scores.append(avg_score)\n",
    "\n",
    "# Print the cross-validation scores for each base model\n",
    "for i, model in enumerate(base_models):\n",
    "    print(f\"Base Model {i+1}: {cv_scores[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174be917",
   "metadata": {},
   "source": [
    "## Meta Model\n",
    "\n",
    "The meta model uses the predictions of the base models to predict $y$. One can thus view the base models as a feature map for the meta model.\n",
    "\n",
    "In order to train the meta model, **we need the predictions of the base models on unseen data** since this is the scenario we would face at inference time. A simple method is to use **out-of-fold predictions** during training:\n",
    "\n",
    "1. separate the data into k folds.\n",
    "2. hold out one of the folds and train the base models on the other folds.\n",
    "3. predict the held out fold using the base models.\n",
    "4. repeat the above two steps k times to obtain out-of-fold predictions for all k folds.\n",
    "5. feed all the out-of-fold prediction as features (training data) to the meta model.\n",
    "\n",
    "\n",
    "### Task 4\n",
    "\n",
    "Implement the out-of-fold method below.\\\n",
    "Calculate the $R^2$-Score on the out-of-fold predictions for each of the base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "afa6379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model 1 - R2 Score (Out-of-fold): 0.33007248077065265\n",
      "Base Model 2 - R2 Score (Out-of-fold): 0.2788744311971052\n",
      "Base Model 3 - R2 Score (Out-of-fold): 0.0006190028696213545\n",
      "Base Model 4 - R2 Score (Out-of-fold): -0.24644357791723825\n"
     ]
    }
   ],
   "source": [
    "def oof_prediction(model: BaseEstimator, X: np.ndarray, y: np.ndarray, k=5) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates out-of-fold predictions.\n",
    "\n",
    "    @Params:\n",
    "        model... class with a .fit and .predict method\n",
    "        X... samples\n",
    "        y... labels\n",
    "\n",
    "    @Returns:\n",
    "        predictions\n",
    "    '''\n",
    "    kf = KFold(n_splits=k)\n",
    "    oof_predictions = np.zeros_like(y)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test).reshape(-1, 1)\n",
    "        oof_predictions[test_index] = y_pred\n",
    "\n",
    "    return oof_predictions\n",
    "\n",
    "# Create a list of base models\n",
    "base_models = [\n",
    "    LinearRegression(),\n",
    "    make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "    KNeighborsRegressor(),\n",
    "    DecisionTreeRegressor()\n",
    "]\n",
    "\n",
    "# Calculate R2 score for out-of-fold predictions for each base model\n",
    "for i, model in enumerate(base_models):\n",
    "    oof_pred = oof_prediction(model, X, y)\n",
    "    r2_oof = r2_score(y, oof_pred)\n",
    "    print(f\"Base Model {i+1} - R2 Score (Out-of-fold): {r2_oof}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1f1a9",
   "metadata": {},
   "source": [
    "Now lets put everything together.\n",
    "\n",
    "### Task 5\n",
    "\n",
    "Implement the following `Stacking` class. Keep in mind the following things:\n",
    "- the meta model is trained on out-of-fold predictions of the base models\n",
    "- the base models are trained on the given dataset\n",
    "- when predicting, we just use the predictions of the base models (no out-of-fold) as input for the meta model\n",
    "\n",
    "Use your class to learn a stacked regressor with **linear regression as meta model** and the base models from Task 3. Evaluate it using crossvalidation (avg. of 10 folds) and compare the score to those of the base models (Task 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "71c17292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "Stacked Regressor: 0.2505126356437329\n",
      "Base Model 1: 0.2355470969430759\n",
      "Base Model 2: 0.1902292194320662\n",
      "Base Model 3: -0.07634595535227609\n",
      "Base Model 4: -0.5315458182226246\n"
     ]
    }
   ],
   "source": [
    "class StackedRegressor(sklearn.base.BaseEstimator):\n",
    "    \n",
    "    def __init__(self, base_models : list, meta_model : sklearn.base.BaseEstimator):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        \n",
    "    def fit(self, X : np.ndarray, y : np.ndarray):\n",
    "        '''\n",
    "        Learns base and meta models.\n",
    "        \n",
    "        @Params:\n",
    "            X... features\n",
    "            y... labels\n",
    "        '''\n",
    "        # TODO: implement\n",
    "        base_pred = np.zeros((X.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            model.fit(X,y)\n",
    "            base_pred[:, i] = oof_prediction(model, X, y).flatten()\n",
    "\n",
    "        self.meta_model.fit(base_pred, y)\n",
    "    \n",
    "    def predict(self, X : np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Given features, predicts labels.\n",
    "        \n",
    "        @Params:\n",
    "            X... features\n",
    "            \n",
    "        @Returns:\n",
    "            labels as array\n",
    "        '''\n",
    "        # TODO: implement\n",
    "        base_pred = np.zeros((X.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            base_pred[:, i] = model.predict(X).flatten()\n",
    "\n",
    "        return self.meta_model.predict(base_pred)\n",
    "    \n",
    "    \n",
    "    def score(self, X, y):\n",
    "        '''\n",
    "        R2-Score, needed for crossvalidation.\n",
    "        \n",
    "        @Params:\n",
    "            X... features\n",
    "            y... labels\n",
    "            \n",
    "        @Returns:\n",
    "            Accuracy when predicting for X.\n",
    "        '''\n",
    "        # TODO: implement\n",
    "        y_pred = self.predict(X)\n",
    "        return r2_score(y, y_pred)\n",
    "\n",
    "    \n",
    "# TODO: fit stacked model\n",
    "\n",
    "# Create the stacked regressor\n",
    "stacked_regressor = StackedRegressor(base_models=base_models, meta_model=LinearRegression())\n",
    "\n",
    "# Fit the stacked regressor\n",
    "stacked_regressor.fit(X, y)\n",
    "\n",
    "# TODO: evaluate with crossvalidation, compare to base models\n",
    "\n",
    "# Evaluate with cross-validation and compare to base models\n",
    "cv_scores_stacked = cross_val_score(stacked_regressor, X, y, cv=10)\n",
    "\n",
    "print(\"Cross-validation scores:\")\n",
    "print(\"Stacked Regressor:\", cv_scores_stacked.mean())\n",
    "for i, model in enumerate(base_models):\n",
    "    print(f\"Base Model {i+1}: {cv_scores[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40740021",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "Use the [scikit-learn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html) to learn a stacked regressor.\\\n",
    "Evaluate it using crossvalidation (avg. of 10 folds) and compare the score to the scores of task 5.\n",
    "\n",
    "Note that minor differences can occur due to a more advanced oof-prediction used in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f00c97f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "Stacked Regressor sklearn: 0.24096347646001465\n",
      "Stacked Regressor custom: 0.2505126356437329\n"
     ]
    }
   ],
   "source": [
    "# TODO: fit sklearn stacked model\n",
    "# Create the stacked regressor\n",
    "base_models = [\n",
    "    ('model1', LinearRegression()),\n",
    "    ('model2', make_pipeline(PolynomialFeatures(degree=2), LinearRegression())),\n",
    "    ('model3', KNeighborsRegressor()),\n",
    "    ('model4', DecisionTreeRegressor())\n",
    "]\n",
    "\n",
    "stacked_regressor = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "# TODO: evaluate with crossvalidation, compare to custom model\n",
    "\n",
    "# Evaluate with cross-validation and compare to base models\n",
    "cv_scores_stacked_sklearn = cross_val_score(stacked_regressor, X, y.flatten(), cv=10)\n",
    "\n",
    "print(\"Cross-validation scores:\")\n",
    "print(\"Stacked Regressor sklearn:\", cv_scores_stacked_sklearn.mean())\n",
    "print(\"Stacked Regressor custom:\", cv_scores_stacked.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550fa29",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "Try at least two different combinations of regressors for base models and meta model and report the average crossvalidation score.\n",
    "[Here](https://scikit-learn.org/stable/supervised_learning.html) you can find an overview page of sklearn estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7839301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23759923956468768, 0.2455401883093745, 0.23496884212583816, 0.21432578336503788, 0.23693584293578263, 0.23865227371221548, 0.0819674713573996, 0.046110316683996955, 0.24006837634160755, 0.25186978749763983]\n"
     ]
    }
   ],
   "source": [
    "# TODO: try different combinations\n",
    "base_models = [\n",
    "    [\n",
    "        ('model1', LinearRegression()),\n",
    "        ('model2', KNeighborsRegressor()),\n",
    "        ('model3', Ridge())\n",
    "    ],\n",
    "    [\n",
    "        ('model1', LinearRegression()),\n",
    "        ('model2', Lasso()),\n",
    "        ('model3', Ridge())\n",
    "    ],\n",
    "    [\n",
    "        ('model1', Ridge()),\n",
    "        ('model2', Lasso()),\n",
    "        ('model3', KNeighborsRegressor())\n",
    "    ],\n",
    "    [\n",
    "        ('model1', Lasso()),\n",
    "        ('model2', DecisionTreeRegressor()),\n",
    "        ('model3', KNeighborsRegressor())\n",
    "    ],\n",
    "    [\n",
    "        ('model1', DecisionTreeRegressor()),\n",
    "        ('model2', LinearRegression()),\n",
    "        ('model3', KNeighborsRegressor())\n",
    "    ]\n",
    "]\n",
    "\n",
    "meta_models = [\n",
    "    LinearRegression(),\n",
    "    make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "]\n",
    "\n",
    "cv_scores = []\n",
    "for models in base_models:\n",
    "    for meta_model in meta_models:\n",
    "        stacked_regressor = StackingRegressor(estimators=models, final_estimator=meta_model)\n",
    "        cv_score = cross_val_score(stacked_regressor, X, y.flatten(), cv=10)\n",
    "        cv_scores.append(np.mean(cv_score))\n",
    "\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6e7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1315e6714f2518a6216a6eec3b047587d10875bf19b853b35d3e5c84c569e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
